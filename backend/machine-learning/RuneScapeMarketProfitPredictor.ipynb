{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "p3qs9Z2RRNQ4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpXswyo2oFBg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import joblib\n",
        "import requests\n",
        "import sqlite3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting Item IDs from the Database"
      ],
      "metadata": {
        "id": "PPFSHqFORQLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get items ids from db\n",
        "db_path = 'prod.db'\n",
        "conn = sqlite3.connect(db_path)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "cursor.execute(\"SELECT item_id FROM items\")\n",
        "item_ids = cursor.fetchall()\n",
        "\n",
        "item_ids = [item[0] for item in item_ids]\n",
        "df_item_ids = pd.DataFrame(item_ids, columns=['item_id'])\n",
        "\n",
        "df_item_ids.to_csv('item_ids.csv', index=False)\n",
        "\n",
        "conn.close()\n",
        "\n",
        "print(\"Item IDs have been saved to 'item_ids.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ms81bwVDqXIN",
        "outputId": "3f8f9613-d71c-46a7-9d38-bb9785111d27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Item IDs have been saved to 'item_ids.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clustering"
      ],
      "metadata": {
        "id": "ZS35vvmp4pbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "item_df = pd.read_csv(\"item_ids.csv\")\n",
        "item_ids = item_df[\"item_id\"].tolist()"
      ],
      "metadata": {
        "id": "skSnavZD4o4h"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def get_price_series(item_id):\n",
        "    url = f\"https://api.weirdgloop.org/exchange/history/rs/all?id={item_id}\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        data = response.json()\n",
        "        if str(item_id) in data:\n",
        "            df = pd.DataFrame(data[str(item_id)])\n",
        "            df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"ms\")\n",
        "            df = df.sort_values(\"timestamp\").reset_index(drop=True)\n",
        "            return df[\"price\"].values\n",
        "        else:\n",
        "            return None\n",
        "    except:\n",
        "        return None"
      ],
      "metadata": {
        "id": "FFZDFdNi4ztz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_series(series, length=100):\n",
        "    series = series[-length:]\n",
        "    if len(series) < length:\n",
        "        pad = [series[-1]] * (length - len(series))\n",
        "        series = np.concatenate([pad, series])\n",
        "    return series"
      ],
      "metadata": {
        "id": "Kl4chEn542dV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import csv\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "item_ids_df = pd.read_csv(\"item_ids.csv\")\n",
        "item_ids = item_ids_df[\"item_id\"].tolist()\n",
        "\n",
        "output_file = \"price_features.csv\"\n",
        "failed_items = []\n",
        "\n",
        "if not os.path.exists(output_file):\n",
        "    with open(output_file, \"w\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"item_id\"] + [f\"diff_{i}\" for i in range(50)])\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "for i, item_id in tqdm(enumerate(item_ids), total=len(item_ids)):\n",
        "    try:\n",
        "        response = requests.get(f\"https://api.weirdgloop.org/exchange/history/rs/all?id={item_id}\")\n",
        "\n",
        "        if response.status_code != 200:\n",
        "            failed_items.append(item_id)\n",
        "            continue\n",
        "\n",
        "        data = response.json()\n",
        "\n",
        "        if str(item_id) not in data or not data[str(item_id)]:\n",
        "            failed_items.append(item_id)\n",
        "            continue\n",
        "\n",
        "        df = pd.DataFrame(data[str(item_id)])\n",
        "        df[\"price_diff\"] = df[\"price\"].diff()\n",
        "        features = df[\"price_diff\"].dropna().tail(50).values\n",
        "\n",
        "        if len(features) == 50:\n",
        "            normalized_features = scaler.fit_transform(features.reshape(-1, 1)).flatten()\n",
        "\n",
        "            with open(output_file, \"a\", newline=\"\") as f:\n",
        "                writer = csv.writer(f)\n",
        "                writer.writerow([item_id] + list(normalized_features))\n",
        "        else:\n",
        "            failed_items.append(item_id)\n",
        "\n",
        "    except Exception as e:\n",
        "        failed_items.append(item_id)\n",
        "\n",
        "pd.DataFrame(failed_items, columns=[\"failed_item_id\"]).to_csv(\"failed_items.csv\", index=False)"
      ],
      "metadata": {
        "id": "NU1vByk346Ad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_df = pd.DataFrame(X)\n",
        "\n",
        "X_df.to_csv(\"item_features.csv\", index=False)"
      ],
      "metadata": {
        "id": "Nuig0qkwB_TP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "n_clusters = 10\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "labels = kmeans.fit_predict(X)\n",
        "\n",
        "cluster_map = pd.DataFrame({\"item_id\": valid_ids, \"cluster\": labels})\n",
        "cluster_map.to_csv(\"item_cluster_map.csv\", index=False)"
      ],
      "metadata": {
        "id": "T8PRH9a947iZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "inertias = []\n",
        "K_range = range(2, 20)\n",
        "\n",
        "for k in K_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(X)\n",
        "    inertias.append(kmeans.inertia_)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(K_range, inertias, marker='o')\n",
        "plt.xlabel(\"Number of Clusters (k)\")\n",
        "plt.ylabel(\"Inertia\")\n",
        "plt.title(\"Elbow Method for Optimal k\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YSc_ufvk5Bo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Testing the Model (One Item)"
      ],
      "metadata": {
        "id": "NVZ1fGZDRHuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# call api\n",
        "url = \"https://api.weirdgloop.org/exchange/history/rs/all?id=2\"\n",
        "\n",
        "response = requests.get(url)\n",
        "data = response.json()\n",
        "\n",
        "item_id = \"2\"\n",
        "if item_id in data:\n",
        "    df = pd.DataFrame(data[item_id])  # convert to df\n",
        "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"ms\")  # Convert timestamp from milliseconds\n",
        "    print(df.head())\n",
        "else:\n",
        "    print(f\"Item ID {item_id} not found in response.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAUYnoNjqC6-",
        "outputId": "877debb6-d441-41cb-e34b-c205d33f075e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  id  price  volume  timestamp\n",
            "0  2    188     NaN 2008-05-21\n",
            "1  2    186     NaN 2008-05-22\n",
            "2  2    186     NaN 2008-05-23\n",
            "3  2    184     NaN 2008-05-24\n",
            "4  2    184     NaN 2008-05-25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create features\n",
        "df[\"prev_price\"] = df[\"price\"].shift(1)\n",
        "X = df[[\"prev_price\"]]  # features\n",
        "y = df[\"price\"]  # target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "sG2oHIcZqMhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train model\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f\"Mean Absolute Error: {mae}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOR27oHiqReJ",
        "outputId": "1b906e65-6f6f-49e0-f363-bc9cc3e85eae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error: 8.019659037963061\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model\n",
        "joblib.dump(model, \"runescape_model.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1d4vHdCqWjA",
        "outputId": "f7258b66-ed4a-49ec-990c-cd40ce6e2876"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['runescape_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load model\n",
        "model = joblib.load(\"runescape_model.pkl\")"
      ],
      "metadata": {
        "id": "wMpaATn9qXPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test prediction\n",
        "latest_price = df[\"prev_price\"].iloc[-1]\n",
        "\n",
        "next_input = pd.DataFrame([[latest_price]], columns=[\"prev_price\"])\n",
        "\n",
        "predicted_price = model.predict(next_input)\n",
        "\n",
        "print(f\"Predicted Next Price: {predicted_price[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXE3TO5fqYP0",
        "outputId": "fe05cff7-fa65-422e-976d-6afe24aea661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Next Price: 1519.801047619048\n"
          ]
        }
      ]
    }
  ]
}